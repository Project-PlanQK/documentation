{
  "examples": [
    {
      "query": "I am a tech lead at Lufhansa consulting. ​\nWe are looking for a way to efficiently solving​\nthe challenges in providing sufficient airspace capacity to avoid airspace congestion. ",
      "reference_contexts": [
        "Lars?"
      ],
      "reference_answer": "The problem of ATFM is described in the ATFM Use Case on PlanQK. Here are the key concepts …, also here is a link to the use case. Using  Kipu’s digitized counterdiabatic quantum optimization (DCQO) algorithms we are  able to solve larger problem than possible.​\nThe service is accessible on our Marketplace. ​",
      "response": "Great to meet you! Addressing airspace capacity and congestion is a classic optimization challenge, and PlanQK offers several quantum and AI-powered solutions that could be highly relevant for your needs.\n\nPlanQK’s managed services platform lets you build, deploy, and execute optimization algorithms—including quantum-accelerated approaches—without worrying about infrastructure or hardware management. You focus on your Python code (or other supported languages), and PlanQK handles the containerization and deployment, exposing your solution via simple HTTP APIs for easy integration with your existing tools and workflows. This means rapid prototyping and deployment for complex problems like airspace allocation, route optimization, and congestion mitigation, with the potential to leverage quantum algorithms for a computational edge over classical methods .\n\nRecommended PlanQK Capabilities for Airspace Optimization:\n- Quantum Optimization Algorithms: Explore quantum-inspired and true quantum solvers for scheduling, routing, and resource allocation problems.\n- Managed Services: Deploy your custom optimization models as scalable, on-demand services. Easily integrate with your operational systems using HTTP APIs [doc1][doc2][doc6].\n- Workflow Orchestration: Combine multiple models/services, including classical and quantum, in automated workflows to solve end-to-end optimization scenarios .\n- Access to Quantum Backends: Run your models on various quantum hardware providers (IBM, D-Wave, Amazon Braket, QuEra, etc.) using PlanQK’s SDKs and managed service framework .\n\nNext Steps:\n1. Explore PlanQK’s quickstart guides for managed services and the CLI to rapidly prototype and deploy a quantum optimization service: source: https://platform.planqk.de/docs/services/managed/introduction\n2. Review available optimization algorithms and use cases relevant to congestion and scheduling on the PlanQK platform: source: https://platform.planqk.de/use-cases\n3. Consider using the workflow editor to orchestrate more complex decision support systems, combining quantum and classical components: source: https://platform.planqk.de/docs/services/orchestration\n4. If you have existing Python optimization code, see how easily it can be adapted to PlanQK’s managed service templates for rapid deployment: source: https://platform.planqk.de/docs/services/managed/runtime-interface\n\nCould you share more specifics about your congestion challenges? For example, are you dealing with flight scheduling, sector allocation, real-time rerouting, or long-term planning? This will help me suggest the most relevant algorithms and templates from PlanQK.\n\nIdentified persona: Business"
    },
    {
      "query": "How can I run my existing Qiskit code on PlanQK's quantum backends?",
      "reference_contexts": [
        "In your Python code you can access the PLANQK quantum backends through the\nPlanqkQuantumProvider class. Import the class and instantiate it as shown below:\nIf you are already logged in with the PLANQK CLI you can create the provider object\nwithout any parameters:\nfrom planqk import PlanqkQuantumProvider  \nprovider = PlanqkQuantumProvider()  \nAlternatively, you can also create the provider object by passing your PLANQK personal\naccess token:\nprovider = PlanqkQuantumProvider(access_token=\"your-access-token\")  \nIf you want to log in with your organization, you can additionally pass the organization id as\na parameter. The organization id can be found in the organization settings on the PLANQK\nPlatform:\nprovider = PlanqkQuantumProvider(organization_id=\"your-organization-id\")  \nAfter you have created the provider object, you can list all backends supported by the\nPLANQK Platform and select the one you want to use."
      ],
      "reference_answer": "Use the PlanqkQuantumProviderfrom the PlanQK Quantum SDK to run your Qiskit code on supported quantum backends.",
      "response": "You can run your existing Qiskit code on PlanQK’s quantum backends using the PLANQK Quantum SDK, which acts as a wrapper for Qiskit and provides seamless integration with the supported quantum hardware and simulators.\n\nHere are the main steps:\n\n1. Install the PLANQK Quantum SDK:\n   - Make sure you have Python 3.11+ installed.\n   - Install the SDK from PyPI:\n     ```bash\n     pip install planqk-quantum\n     ```\n   - This SDK retains the same functionality and syntax as Qiskit, so you don’t need to modify your existing code structure [doc1].\n\n2. Acquire a PlanQK Access Token:\n   - Sign up or log in to your PLANQK account.\n   - Create or copy your personal quantum access token from your account settings.\n   - Store this token securely; you'll need it to authenticate your requests and track usage costs [doc1].\n\n3. Update Your Qiskit Code to Use PlanQKQuantumProvider:\n   - Import PlanQKQuantumProvider and use your access token:\n     ```python\n     from planqk.qiskit import PlanqkQuantumProvider\n     planqk_token = \"YOUR_ACCESS_TOKEN\"\n     provider = PlanqkQuantumProvider(access_token=planqk_token)\n     ```\n   - If running inside a PLANQK service, the token is set automatically by the platform [doc1][doc2].\n\n4. Select a Backend and Execute:\n   - List available backends:\n     ```python\n     backends = provider.backends()\n     ```\n   - Select a backend (e.g., IonQ simulator):\n     ```python\n     backend = provider.get_backend(\"azure.ionq.simulator\")\n     ```\n   - Prepare and transpile your circuit as usual, then execute:\n     ```python\n     from qiskit import QuantumCircuit, transpile\n     circuit = QuantumCircuit(3, 3)\n     circuit.h(0)\n     circuit.cx(0, 1)\n     circuit.cx(1, 2)\n     circuit.measure(range(3), range(3))\n     circuit = transpile(circuit, backend)\n     job = backend.run(circuit, shots=1000)\n     ```\n   - You can retrieve, monitor, or cancel your job as needed [doc2].\n\n5. Cost Awareness:\n   - Running jobs incurs costs based on backend and number of shots.\n   - Check the pricing page for backend-specific details [doc2].\n\nFor more details, see the full tutorial:\nsource: https://docs.planqk.de/tutorials/tutorial-qiskit-with-planqk-sdk.html\n\nAre you looking to run your Qiskit code from a local environment, or do you want to deploy it as a managed service within PlanQK? Let me know if you need a step-by-step guide for either scenario!\n\nIdentified persona: Technical"
    },
    {
      "query": "How do I authenticate with the PlanQK SDK to run quantum programs?",
      "reference_contexts": [
        "If you are already logged in with the PLANQK CLI you can create the provider object\nwithout any parameters:\nfrom planqk import PlanqkQuantumProvider\nprovider = PlanqkQuantumProvider()\nAlternatively, you can also create the provider object by passing your PLANQK personal\naccess token:\nprovider = PlanqkQuantumProvider(access_token=\"your-access-token\")"
      ],
      "reference_answer": "You can authenticate via CLI with planqk login -t <your token> or provide the access token directly when instantiating the provider in code.",
      "response": "To authenticate with the PlanQK Quantum SDK and run quantum programs, you need a valid PlanQK account and a quantum access token. Here’s the typical workflow:\n\n1. Create/Log in to your PlanQK account.\n2. Obtain your access token:\n   - Log in to the PlanQK platform and copy your personal access token from the welcome page.\n   - Alternatively, you can create a dedicated access token in your user settings for use in your code.\n3. Use the access token in your code:\n   - When initializing the PlanqkQuantumProvider object, pass your access token as shown below:\n\n```python\nfrom planqk.qiskit import PlanqkQuantumProvider\n\nplanqk_token = \"YOUR_ACCESS_TOKEN\"\nprovider = PlanqkQuantumProvider(access_token=planqk_token)\n```\n\n- If you run your code inside a PlanQK service, the access token is set automatically by the platform, so you don’t need to provide it explicitly. If set, it will be replaced by the service token.\n\nThis process ensures that your requests to the PlanQK platform are authenticated and that usage costs are tracked accordingly.\n\nWould you like help with generating or managing access tokens, or are you ready to start executing quantum jobs?  \nsource: https://docs.planqk.de/tutorials/tutorial-qiskit-with-planqk-sdk.html\n\nIdentified persona: Technical"
    },
    {
      "query": "How do I use the PlanQK CLI to manage my implementations?",
      "reference_contexts": [
        "Then install the PLANQK CLI globally using npm:\nnpm install -g @planqk/planqk-cli\n[...]\nplanqk init\nDESCRIPTION\nInitialize a PLANQK project to create a service.\nEXAMPLES\n$ planqk init\n[...]\nplanqk up\nDESCRIPTION\nCreates or updates a PLANQK Service\nEXAMPLES\n$ planqk up\n[...]\nplanqk run [SERVICEID]\nDESCRIPTION\nCreates a job execution of a PLANQK Service\nEXAMPLES\n$ planqk run\n$ planqk run --detached\n$ planqk run -d '{\"values\": [10,12]}' -p '{\"round_up\": true}'\n$ planqk run --data-file=./input/data.json --params-file=./input/params.json"
      ],
      "reference_answer": "Install the CLI via npm install -g @planqk/planqk-cli and use commands like planqk init, planqk up, and planqk run to manage implementations.",
      "response": "To manage your implementations with the PlanQK CLI, you'll follow a sequence of steps that cover project initialization, code upload, and service creation. Here’s a concise workflow:\n\n1. Install the PlanQK CLI:\n   - Make sure Node.js (v18+) and npm are installed.\n   - Install the CLI globally with:\n     ```bash\n     npm install -g @planqk/planqk-cli\n     ```\n   - For more commands and details, check the CLI reference.\n   - Source: https://docs.planqk.de/quickstart.html [doc2]\n\n2. Initialize a new implementation project:\n   - Run:\n     ```bash\n     planqk init\n     ```\n   - Choose a name for your service, select a starter template (e.g., Docker Python Starter), and configure resources as prompted.\n   - This creates a new project folder with starter code and configuration.\n   - Source: https://docs.planqk.de/implementations/create-a-service.html [doc1]\n\n3. Create an Implementation on PlanQK:\n   - Go to the \"Create Implementation\" page on the PlanQK platform.\n   - Enter a name and create the implementation.\n   - Source: https://docs.planqk.de/implementations/getting-started.html [doc4]\n\n4. Upload your code to the Implementation:\n   - Clone your implementation repo using the command provided on the PlanQK UI (requires your personal access token for authentication).\n     ```bash\n     git clone https://planqk:<personal-access-token>@git.platform.planqk.de/<your-user-id>/<implementation-name>.git\n     cd <implementation-name>\n     ```\n   - Add or modify files (e.g., README.md) and push changes:\n     ```bash\n     git add .\n     git commit -m \"Initial commit\"\n     git push\n     ```\n   - Source: https://docs.planqk.de/implementations/getting-started.html [doc6]\n\n5. Create a Managed Service from your Implementation:\n   - If your code includes a Dockerfile, you'll see the \"Create Service\" button on your implementation page.\n   - Click to create a PlanQK managed service based on your implementation.\n   - You can view and manage your services via the Services page.\n   - Source: https://docs.planqk.de/implementations/create-a-service.html [doc1]\n\nWould you like guidance on a specific CLI command or a step in the workflow? Are you setting up a quantum or classical service?\n\nIdentified persona: Technical"
    },
    {
      "query": "How do I create a personal access token for authentication on PlanQK?",
      "reference_contexts": [
        "To create a personal access token to your account, go to the user-menu in the top right\ncorner and click on \"Settings\". Under \"Personal Access Tokens\" you can create new\npersonal access tokens and manage existing ones."
      ],
      "reference_answer": "Go to your user settings and create a new token under “Personal Access Tokens.”",
      "response": "To create a personal access token for authentication on PlanQK, follow these steps:\n\n1. Log in to your PlanQK account.\n2. Go to the user-menu in the top right corner and click on \"Settings.\"\n3. Under the \"Personal Access Tokens\" section, you can create new personal access tokens and manage existing ones.\n4. Use your personal access token to authenticate with the PlanQK CLI, SDK, or any custom application that interacts with the PlanQK Platform API.\n\nNote: Personal access tokens can only be created for user accounts, but you can use your token to interact with organizations you are a member of. For more details, see the official documentation:\nsource: https://docs.planqk.de/manage-access-tokens.html\n\nWould you like guidance on how to use your token for CLI or SDK authentication next?\n\nIdentified persona: Technical"
    },
    {
      "query": "How do I get started creating my first implementation on PlanQK?",
      "reference_contexts": [
        "1. To create a new Implementation, visit the Create Implementation page.\n2. Enter a name for your implementation and click on the \"Create\" button.\n[...]\nMoreover, the empty implementation page provides you a set of command line instructions to clone the repository and start working on your implementation. In the following we will go through the steps to clone the repository and add a README file.\nDownloading the implementation to your local machine is called cloning. You can clone the implementation and navigate to it using the following commands:\ngit clone https://planqk:<personal-access-token>@git.platform.planqk.de/<your-user-id>/<implementation-name>.git\ncd <implementation-name>"
      ],
      "reference_answer": "Create an implementation via the platform, clone the repo locally, and add your files.",
      "response": "To get started with your first implementation on PlanQK, follow these steps:\n\n1. Prerequisites:  \n   - Make sure you have Git installed on your machine. If you don't have it yet, download and install Git for your operating system.\n\n2. Create an Implementation:  \n   - Visit the Create Implementation page on PlanQK.\n   - Enter a name for your implementation and click the \"Create\" button.\n   - After creation, you'll see a page for your new implementation. It will show command-line instructions to clone the repository to your local machine.\n\n3. Clone the Repository:  \n   - Use the provided git clone command (which includes the correct repository URL and your personal access token for authentication).\n   - Example:\n     ```bash\n     git clone https://planqk:<personal-access-token>@git.platform.planqk.de/<your-user-id>/<implementation-name>.git\n     cd <implementation-name>\n     ```\n   - You need at least 'Viewer' permissions for the repository to clone it.\n\n4. Add a README:  \n   - Create a README.md file to describe your implementation.\n   - Example:\n     ```bash\n     touch README.md\n     ```\n   - Add content to it as needed using Markdown.\n\n5. Push Your Changes:  \n   - Commit and push your changes back to the remote repository.\n\nThese steps will set up your first implementation. You can then proceed to add code, documentation, or further configuration as needed. For more details and step-by-step guidance, check out the official documentation:\n\nsource: https://docs.planqk.de/implementations/getting-started.html\n\nWould you like help with initializing a starter project, or do you have a specific use case in mind for your implementation?\n\nIdentified persona: Technical"
    },
    {
      "query": "How do I add other users to my implementation?",
      "reference_contexts": [
        "If you want to grant certain users access to your implementation, you can add them as\nmembers. A member can have the role Viewer, Maintainer or Owner.\nViewer: Can see the implementation and its code, but cannot make any changes.\nMaintainer: Has all the rights of a Viewer and can make changes to the code.\nOwner: Has all rights of a Maintainer and can manage the implementation settings, e.g.,\nadding users, changing the visibility, and deleting the implementation."
      ],
      "reference_answer": "In your implementation settings, you can assign roles like Viewer, Maintainer, or Owner.",
      "response": "To add other users to your implementation on PlanQK, you need to manage members via the implementation settings. Here’s how you can do it:\n\n- Go to the settings of your implementation.\n- In the \"Managing Members\" section, you can add users as members.\n- When adding a member, you can assign them one of these roles:\n  - Viewer: Can see the implementation and its code, but cannot make any changes.\n  - Maintainer: Can view and also make changes to the code.\n  - Owner: Has all rights, including managing settings, adding/removing users, changing visibility, and deleting the implementation.\n\nThis way, you can collaborate with others by giving them the appropriate level of access to your implementation. All PlanQK users can be added as members, but only those with the right roles can make changes or manage the implementation settings.\n\nFor full details, check out the official documentation:\nsource: https://docs.planqk.de/implementations/settings.html\n\nAre you planning to add users from your organization or external collaborators? Let me know if you need guidance on role assignment or organization setup.\n\nIdentified persona: Technical"
    },
    {
      "query": "How can I quickly get started with developing and running a quantum program on PlanQK?",
      "reference_contexts": [
        "A crash course on using the PLANQK Platform to run an entire quantum workflow, from\ndevelopment to deployment .\n[...]\nTo install the PLANQK CLI, you must install Node.js 18 or higher and the npm command line\ninterface using either a Node version manager or a Node installer.\nThen install the PLANQK CLI globally using npm:\nnpm install -g @planqk/planqk-cli  \n[...]\nLogin to your account using your access token:\nplanqk login -t <your access token>  \nCreate your first project by running the following command:\nplanqk init  \n[...]\nLearn how to use our SDK to interact with our supported quantum backends.\nCheck out our tutorials to get started with the platform."
      ],
      "reference_answer": "Follow the quickstart guide to install the CLI and SDK and run your first quantum program.",
      "response": "To quickly get started with developing and running a quantum program on PlanQK, you can follow these streamlined steps:\n\n1. Set Up Your Environment\n- Install the PLANQK Quantum SDK: You’ll need Python 3.11+ installed. The SDK can be added via pip:\n  ```\n  pip install planqk-quantum\n  ```\n  This SDK wraps Qiskit 1.0, allowing you to use familiar Qiskit syntax and functionality for your quantum programs on PLANQK backends [doc7].\n\n2. Obtain Access Credentials\n- Sign up or log in to PLANQK and generate a quantum access token. This token authenticates your requests and tracks usage costs. You can find or create this token in your user settings [doc7].\n\n3. Write and Execute Quantum Code\n- Use the PlanqkQuantumProvider in your Python code and pass your access token:\n  ```python\n  from planqk.qiskit import PlanqkQuantumProvider\n  provider = PlanqkQuantumProvider(access_token=\"YOUR_ACCESS_TOKEN\")\n  ```\n- List available backends and select one (e.g., Azure IonQ simulator):\n  ```python\n  backends = provider.backends()\n  backend = provider.get_backend(\"azure.ionq.simulator\")\n  ```\n- Create and execute a Qiskit circuit:\n  ```python\n  from qiskit import QuantumCircuit, transpile\n  circuit = QuantumCircuit(3, 3)\n  circuit.h(0)\n  circuit.cx(0, 1)\n  circuit.cx(1, 2)\n  circuit.measure(range(3), range(3))\n  circuit = transpile(circuit, backend)\n  job = backend.run(circuit, shots=1000)\n  ```\n  You can retrieve the job status and results as needed [doc6].\n\n4. Use the CLI for Rapid Testing\n- Alternatively, you can use the PLANQK CLI to initialize, upload, and run your quantum service projects:\n  - Initialize a starter project:\n    ```\n    planqk init\n    ```\n  - Run your service with example data:\n    ```\n    planqk run\n    ```\n  - After execution, view your job result online [doc9].\n\n5. Manage Jobs and Results\n- Visit the Quantum Jobs page on the platform to monitor submitted jobs, view results, and download job outputs [doc2].\n\n6. Explore Tutorials and Docs\n- Check out the PLANQK Tutorials for step-by-step guides and practical examples to accelerate your onboarding:\n  source: https://docs.planqk.de/quickstart.html\n\nWould you like a hands-on example, or are you interested in a particular backend or quantum algorithm? Let me know your programming experience or target use case so I can tailor further guidance!\n\nIdentified persona: Technical"
    },
    {
      "query": "Is there a simple example to test PlanQK’s functionality?",
      "reference_contexts": [
        "The starter templates implement quantum random number generation using either the IonQ Simulator or the Qiskit Aer Simulator."
      ],
      "reference_answer": "Yes, the coin toss example shows how to build and run a basic quantum program.",
      "response": "Yes! PlanQK provides a simple example to quickly test its functionality: the Quantum Coin Toss. This example is available as a ready-to-run Jupyter notebook (coin_toss.ipynb) that demonstrates how to execute quantum algorithms using the PlanQK platform. You can run the code immediately and see results—for instance, getting counts from a quantum backend after running a basic circuit. For an even smoother start, PlanQK offers a Python Starter template that bootstraps all required files so you can run the coin toss example as a service with just a few commands.\n\nHere’s how you can get started:\n1. Run planqk init and select Python Starter to set up your first project.\n2. Test your service locally using the provided requirements.txt and code.\n3. Explore the Jupyter notebook for hands-on experience.\n\nThis is the recommended first step for new users to get familiar with PlanQK’s workflows and quantum backend integration.\n\nWould you like detailed step-by-step instructions or a link to the quickstart guide?  \nsource: https://docs.planqk.de/quickstart.html\n\nIdentified persona: Business"
    },
    {
      "query": "Are there templates to help me create a new service?",
      "reference_contexts": [
        "The PLANQK CLI provides you with a set of starter templates to help you get started\nquickly with your quantum services. You can see the full list of available templates in our\nGitLab repository. In this tutorial we will use the Docker Python Starter template to\ncreate a new service based on custom Docker containers. To initialize the project, run the\nfollowing command in your terminal:\nplanqk init "
      ],
      "reference_answer": "Yes, the PlanQK CLI provides starter templates like the Docker-Python starter template.",
      "response": "Yes, PlanQK provides starter templates to help you quickly bootstrap new services! When you use the PLANQK CLI, you'll be prompted to select a starter template. There are options such as:\n\n- Python Starter: Ideal for quantum services written in Python and comes pre-configured for typical use cases.\n- Docker Starter: Lets you create a service based on custom Docker containers—great if you need OS-level packages not included in the Python template, want to use another language (like Go or Rust), or require guaranteed reproducible builds.\n\nTo get started, simply run planqk init in your terminal, and choose your preferred template during the interactive setup. The CLI will create a project folder with the necessary files and structure. You can view all available templates in PlanQK's GitLab repository and consult the README file in your generated project for more details.\n\nWould you like guidance on choosing the right template for your use case or help with the next steps in your service setup?\nsource: https://docs.planqk.de/implementations/create-a-service.html\nsource: https://docs.planqk.de/services/managed/custom-containers.html\nsource: https://docs.planqk.de/quickstart.html\n\nIdentified persona: Technical"
    },
    {
      "query": "Can I reuse previously developed services for similar use cases?",
      "reference_contexts": [
        "Implementations are hosted as Git repositories, which means that version control and\ncollaboration are core elements of PLANQK. In a nutshell, an implementation (also known\nas a repo or repository) is a place where code and assets can be stored to back up your\nwork, share it with the community, and work in a team."
      ],
      "reference_answer": "Yes, services can be stored, managed, and reused via the platform.",
      "response": "Absolutely! On PlanQK, you can reuse previously developed services for similar use cases very efficiently. This is enabled through Service Orchestration, which lets you build larger services by composing existing ones into workflows. You can set up a workflow where services are called in a defined order, and the results from one service can be used as input for another, all typically without writing new code. This means any service you've already developed can be integrated into new solutions for related problems, speeding up development and promoting modularity [doc1].\n\nAdditionally, when describing or publishing a use case in the PlanQK Community section, you can link existing algorithms, implementations, data pools, and quantum apps that were used or are relevant. This makes it easy to reference and reuse services across multiple use cases, ensuring that your previous work adds value to new projects [doc5][doc8].\n\nWould you like guidance on how to orchestrate services for a specific use case or details on linking existing implementations in the community section?\n\nIdentified persona: Technical"
    },
    {
      "query": "How can I check whether my model processes the provided data correctly?",
      "reference_contexts": [
        "As a service host, you can view the input data and results of jobs initiated by your\nservice’s executions. Additionally, you have the ability to cancel any jobs that are queued\nfrom a service execution."
      ],
      "reference_answer": "Use job monitoring features to inspect logs and outputs to validate correct data usage.",
      "response": "To check whether your model processes the provided data correctly on PlanQK, you have several options for testing and validation:\n\n1. Local Testing with PLANQK CLI and API Docs\nYou can run your service locally using the PLANQK CLI. This exposes the same HTTP endpoints as the deployed service, allowing you to interactively test your model’s input and output:\n\n- Start your local server: \n  ```bash\n  planqk serve\n  ```\n- Open http://localhost:8081/docs to access the interactive API documentation.\n- Use the POST / operation: Click \"Try it out,\" provide a sample JSON payload for \"data\", and execute.\n- The response will include an execution ID. Use GET /{id} to check the status.\n- Once the status is SUCCEEDED, use GET /{id}/result to retrieve and inspect the output. This allows you to verify if the returned results match your expectations for the provided input data.\n\nThis approach gives you a quick feedback loop for debugging and validation before deploying your model to the platform source: https://docs.planqk.de/quickstart.html.\n\n2. Service Output Inspection\nThe PLANQK Service API is designed to return results as JSON-serializable objects. You can inspect the output of your run() method—whether it’s a dictionary or Pydantic model—by retrieving the result via the GET /{id}/result endpoint. This lets you confirm that the output format and content are correct for your test inputs source: https://docs.planqk.de/services/managed-runtime-interface.html.\n\n3. Data Pools for Larger or Reusable Inputs\nIf you want to test your model with larger datasets or reuse shared data, you can leverage PlanQK’s data pool feature. Reference the data pool file in your input payload and run the service as described above. This ensures your model correctly handles data from both direct JSON input and shared data pools source: https://docs.planqk.de/services/using-a-service.html.\n\nWould you like step-by-step guidance for a specific model or input type? Or do you need help interpreting your model's output? Let me know what kind of service or data you’re working with, and I can provide more tailored instructions!\n\nIdentified persona: Technical"
    },
    {
      "query": "Can I test a service without having programming knowledge?",
      "reference_contexts": [
        "As your service code includes a Dockerfile, you should see the \"Create Service\" button in\nthe action bar of your implementation page. Click on the button to create a new PLANQK\nservice based on your implementation. Navigate to the Services page to see your new\nservice. Congratulations, you have successfully created a PLANQK service based on your\nimplementation."
      ],
      "reference_answer": "Yes, services can be executed and managed via the UI without writing code.",
      "response": "Absolutely! On PlanQK, you can test and use services without needing any programming knowledge. The platform is designed to be accessible for users of all backgrounds—including those who are not developers.\n\nHere’s how you can do it:\n\n- Service Orchestration: PlanQK provides a workflow editor based on BPMN (Business Process Model and Notation), which lets you build larger services from existing ones by visually arranging service calls in a workflow. You can set up and deploy these workflows with no code required. This way, you can connect different services and use their outputs as inputs for others, all through a graphical interface rather than writing scripts or code. This is perfect for users who prefer visual tools over programming! source: https://docs.planqk.de/services/orchestration/introduction.html\n\n- Using Services: You can subscribe to services directly from the PlanQK platform (either internally published or via the marketplace). The platform guides you through the process with buttons and dialogs—no coding necessary. After subscribing, you can execute services by providing input data and parameters using easy-to-follow forms or by using pre-defined workflows. source: https://docs.planqk.de/services/using-a-service.html\n\n- Demos: PlanQK offers deployable demos and starter templates that you can launch and interact with via the web interface. These demos are designed for quick onboarding and allow you to experiment with quantum and AI services without technical setup. source: https://docs.planqk.de/services/using-a-service.html\n\nWould you like guidance on using the workflow editor, subscribing to a service, or launching a demo? Let me know your area of interest or what you want to test, and I’ll walk you through the steps!\n\nIdentified persona: Business"
    },
    {
      "query": "What permissions do team members have based on their role in an organization?",
      "reference_contexts": [
        "Under the menu item \\\"Members\\\" you can easily add members to the organization and assign them one of multiple roles (similar to the roles associated to an algorithm or an implementation):\nViewer: Can see the content of the organization, but cannot edit or create content.\nMaintainer: Can create new content, edit existing content, but cannot delete content.\nOwner: Can create, edit and delete whole content of the organization. Owner can add new members, assign them different roles, and can delete members. Of course, the owner can see the entire organization profile and edit it"
      ],
      "reference_answer": "Roles like \"Owner\", \"Maintainer\", and \"Viewer\" grant different levels of access and editing rights.",
      "response": "Team members in a PlanQK organization can be assigned one of several roles, each with different permissions:\n\n- Viewer: Can see the content of the organization, but cannot edit or create content.\n- Maintainer: Can create new content and edit existing content, but cannot delete content.\n- Owner: Can create, edit, and delete all content of the organization. Owners can also add new members, assign roles, and remove members. They have full control over the organization profile and its settings.\n\nMembers are invited via email, and must confirm the invitation to gain access. It's important to select the correct account context before creating new content, as you cannot change its context after creation (i.e., you can't move content between personal and organizational contexts later) [doc2].\n\nWould you like details on how these roles apply specifically to algorithms, implementations, or data pools within your organization?\n\nIdentified persona: Business"
    },
    {
      "query": "How can I limit resource usage during service setup to stay within budget?",
      "reference_contexts": [
        "resources object Required. The resource conﬁguration of your service. [...] resources.cpu number Required. The number of virtual CPU cores to allocate for your service. resources.memory number Required. The amount of memory in GB to allocate for your service. resources.gpu object The GPU conﬁguration of your service. resources.gpu.type string The type of GPU to allocate for your service. One of NVIDIA_TESLA_T4 or NVIDIA_TESLA_V100. resources.gpu.count number The number of GPUs to allocate for your service"
      ],
      "reference_answer": "Use the planqk.json file to configure CPU, RAM, and GPU specifically to control cost.",
      "response": "To limit resource usage during service setup on PlanQK and help stay within your budget, you should leverage the built-in resource limits and deployment strategies provided by the platform:\n\n- When you deploy a Demo or service, PlanQK automatically sets resource limits: each deployed Demo is restricted to 1 CPU and 512 MiB of memory, and it automatically scales to zero when not in use. This means your service won’t consume resources (and incur costs) when idle, helping you control expenses without manual intervention [doc2].\n- For further control, you can monitor your deployments and usage through the PlanQK dashboard, and ensure that you only scale up resources or run jobs when necessary.\n- If you have specific requirements (for example, deploying custom Docker containers with more stringent resource controls), you can configure these during service setup. Review the documentation for advanced service configuration options if needed.\n\nWould you like guidance on monitoring resource usage or tips for optimizing your service’s runtime? You can also check the pricing page for more details on how resource usage translates to cost on PlanQK.\n\nsource: https://docs.planqk.de/demos/deploy-demo.html\n\nIdentified persona: Business"
    },
    {
      "query": "Where can I view and interpret the results of my analyses?",
      "reference_contexts": [
        "By clicking the action button on the right side of each job, you can perform the following actions: Retrieve Inputs & Results: Download your quantum job inputs and results (after the job has completed) directly through the UI"
      ],
      "reference_answer": "Job results can be accessed via the dashboard or API and used for further evaluation.",
      "response": "You can view and interpret the results of your quantum analyses by visiting the Quantum Jobs page on the PlanQK platform. This page provides a comprehensive overview of all quantum jobs or tasks you've submitted using the PlanQK SDK. Once a job has completed, you can download both the inputs and the results directly through the UI for further analysis. If you are a member of an organization, you can switch your account context to view jobs submitted by your organization as well.\n\nTo access this, click on your name in the upper right corner to switch contexts, then navigate to the Quantum Jobs page. For each job, you can use the action button to retrieve results, download inputs, or cancel queued jobs. This makes it easy to manage and interpret results from your quantum analyses in one central location.\n\nFor more details, visit: source: https://docs.planqk.de/manage-quantum-jobs.html\n\nIdentified persona: Technical"
    },
    {
      "query": "Is it possible to compare two services in terms of efficiency and runtime?",
      "reference_contexts": [
        "PLANQK does not offer direct comparison tools, but job metrics can be manually analyzed"
      ],
      "reference_answer": "PlanQK does not offer direct comparison tools, but job metrics can be manually analyzed.",
      "response": "Yes, you can compare two services in terms of efficiency and runtime on the PlanQK platform, but the process involves a bit of hands-on experimentation and data collection. Here’s how you can approach it:\n\n1. Subscribe to Both Services  \nFirst, ensure you have access to both services you want to compare. You can subscribe to services either internally (for your organization) or via the PlanQK Marketplace. Once subscribed, you’ll receive the endpoint URLs and can execute the services as needed [doc1][doc9].\n\n2. Execute Each Service with the Same Input  \nUse the same input data and parameters when invoking both services to ensure a fair comparison. You’ll use the service API (typically a POST request with JSON input) to trigger execution [doc3][doc8][doc9].\n\n3. Collect Runtime Data  \nPlanQK services execute asynchronously, meaning you submit a job and then poll endpoints to check status and retrieve results. To compare runtime:\n- Record the submission time of your job.\n- Poll for status until completion and note the finish time.\n- The difference gives you the execution time for each service .\n\n4. Assess Efficiency  \nEfficiency can refer to resource usage (CPU, memory, GPU), accuracy, or other performance metrics depending on your service’s purpose. You can:\n- Check the resource allocation defined in each service’s planqk.json (e.g., CPU, memory, GPU type/count) [doc6].\n- Analyze the output quality, error rates, or result completeness based on your application needs.\n\n5. Repeat as Needed  \nRun several tests with different datasets or parameters to get statistically significant results.\n\nIf you need a more automated or visual approach, consider using PlanQK’s Service Orchestration and Workflow Editor to set up comparative workflows and aggregate results more easily [doc4].\n\nWould you like step-by-step guidance for setting up such a comparison, or do you already have specific services in mind? If you share more details, I can help tailor the process to your needs!\n\nIdentified persona: Technical"
    },
    {
      "query": "Which quantum approach is applied in the air cargo optimization?",
      "reference_contexts": [
        "Quantum annealing and hybrid solvers are used to optimize the routing problem."
      ],
      "reference_answer": "D-Wave's hybrid quantum-classical solvers were applied to the problem.",
      "response": "The air cargo optimization use case on PlanQK typically leverages quantum algorithms to solve complex logistical and combinatorial problems, such as optimizing cargo loading, routing, and scheduling. These tasks often involve large-scale optimization challenges—like maximizing cargo space utilization, minimizing costs, or ensuring timely deliveries—which are well-suited for quantum computing approaches such as Quantum Approximate Optimization Algorithm (QAOA), Variational Quantum Eigensolver (VQE), or Quantum Annealing.\n\nPlanQK allows users to map these industrial problems onto mathematical formulations (e.g., Quadratic Unconstrained Binary Optimization or QUBO) that can be solved using quantum backends including gate-based or annealing quantum computers. The platform provides documentation, tutorials, and community-shared use cases that describe how such optimization problems are translated into quantum algorithms and then executed on quantum hardware or simulators.\n\nIf you want to dive deeper, the “Use Cases” section in the PlanQK documentation provides examples and details about the problem mapping, the quantum algorithms applied, and the workflow from problem statement to quantum execution. You’ll also find information about associated algorithms, implementations, and data pools relevant to air cargo optimization.\n\nWould you like a step-by-step guide or examples of how to set up an air cargo optimization workflow using PlanQK’s platform and SDKs?\n\nsource: https://docs.planqk.de/community/use-cases.html\n\nIdentified persona: Business"
    },
    {
      "query": "What kind of quantum ML model was tested in the fraud use case?",
      "reference_contexts": [
        "A variational quantum classifier was evaluated against classical baselines."
      ],
      "reference_answer": "A variational quantum circuit was used for binary classification.",
      "response": "The retrieved documents do not specify the exact quantum machine learning (ML) model that was tested in the fraud use case. However, they do describe how to document use cases on the PlanQK platform, including the process of summarizing the use case, providing a detailed description, and listing related algorithms and implementations. This information is typically included in the \"Details\" and \"Relations\" tabs when creating or browsing use cases, allowing users to see which quantum algorithms or models are associated with a given use case, such as fraud detection. For the most precise information about the quantum ML model used in the fraud use case, you would need to consult the specific use case entry on the PlanQK platform, where the associated algorithms and implementations should be documented in detail[doc1][doc5].\n\nWould you like guidance on how to locate or contribute detailed model information for a use case within the PlanQK community? You can also explore published use cases and their related models by visiting the Community Use Cases section: source: https://docs.planqk.de/community/use-cases.html\n\nIdentified persona: Technical"
    },
    {
      "query": "Does the quantum-enhanced image model show any measurable improvement?",
      "reference_contexts": [
        "Yes, experiments showed competitive accuracy compared to classical-only models."
      ],
      "reference_answer": "The hybrid models demonstrated similar performance with reduced parameters.",
      "response": "Based on the retrieved documents, there is no specific information provided regarding the performance or measurable improvement of a quantum-enhanced image model. The documents cover topics such as how to structure input/output for PLANQK services, how to deploy services, manage quantum jobs, and use Markdown/LaTeX in documentation, but do not mention evaluation results or benchmark data for quantum-enhanced image models.\n\nIf you're interested in performance comparisons, I recommend exploring the PlanQK Use Cases section or searching for documented benchmarks or case studies within the PlanQK platform. Would you like guidance on where to find relevant use cases or how to evaluate model performance on PlanQK? \n\nIdentified persona: Business"
    },
    {
      "query": "How is quantum computing used for cybersecurity anomaly detection?",
      "reference_contexts": [
        "Quantum machine learning models are trained to identify unusual access patterns in network data."
      ],
      "reference_answer": "Quantum ML is used to identify outliers in cybersecurity-relevant datasets.",
      "response": "Quantum computing is being explored in cybersecurity anomaly detection primarily for its ability to process and analyze large, complex datasets much faster than classical computers. Here’s how quantum technologies are applied in this context:\n\n1. Quantum Machine Learning Algorithms: Quantum computers can run machine learning algorithms on large-scale security logs or network traffic data. Algorithms like Quantum Support Vector Machines (QSVM) or Quantum Principal Component Analysis (QPCA) can identify outliers or suspicious patterns that may indicate cyber threats. The promise is faster training and improved accuracy for anomaly detection models.\n\n2. Quantum-Enhanced Feature Selection: Quantum algorithms can help with selecting the most relevant features in high-dimensional cybersecurity datasets. This improves model performance and reduces the computational effort required for detection.\n\n3. Optimization for Threat Response: Quantum optimization algorithms (e.g., QUBO solvers on D-Wave) can be used to quickly identify optimal responses or containment strategies in complex network environments when an anomaly is detected.\n\nPlanQK’s platform supports these approaches with quantum backends and SDKs for developing and deploying quantum-enhanced anomaly detection services. You can:\n- Explore available quantum machine learning algorithms and optimization routines.\n- Deploy your own quantum-powered anomaly detection service using PlanQK’s starter templates.\n- Integrate with quantum backends like D-Wave and IBM Quantum for experimentation and scale.\n\nIf you’re interested in building a quantum anomaly detection service, I recommend starting with the Quantum SDK and relevant tutorials on PlanQK:\n- Quantum SDK Overview: source: https://docs.planqk.de/quickstart.html\n- Tutorials for quantum machine learning and optimization: source: https://docs.planqk.de/tutorials/\n\nWould you like guidance on a specific use case, or help with starting a quantum anomaly detection project on PlanQK?\n\nIdentified persona: Business"
    },
    {
      "query": "What benefits could this approach bring to a company’s IT security department?",
      "reference_contexts": [
        "Early detection of network anomalies can reduce reaction time and prevent breaches."
      ],
      "reference_answer": "Quantum-enhanced anomaly detection enables faster threat response.",
      "response": "PlanQK's Managed Services approach can bring several concrete benefits to a company's IT security department:\n\n1. Reduced Infrastructure Overhead: By using PlanQK Managed Services, your team doesn't have to manage quantum or AI infrastructure, patch servers, or worry about hardware upgrades. This reduces attack surfaces and helps keep your IT environment streamlined and secure, as PlanQK handles containerization and deployment for you [doc1].\n\n2. Controlled Access & Sharing: Services can be securely shared with colleagues or external partners using standardized HTTP APIs. This simplifies authentication and authorization management, and supports secure collaboration without exposing internal systems .\n\n3. Compliance & Reproducibility: If you require custom security controls (e.g., installing specific OS-level packages or using unsupported languages), PlanQK enables containerized deployments with Docker. This ensures you can meet compliance requirements and guarantee reproducible, secure builds—critical for security audits and maintaining regulatory standards [doc2][doc3].\n\n4. Automated Updates & Templates: PlanQK regularly updates its templates for improved security and performance, helping you stay ahead of vulnerabilities. If strict reproducibility is needed, Docker containers can be locked to your configuration, ensuring your runtime matches your local, tested environment [doc2][doc3].\n\n5. Simplified Data Input & Output: All service input is currently restricted to JSON, limiting exposure to risky file types and simplifying validation, which helps prevent common security issues like injection attacks [doc4].\n\nWould you like more details on how PlanQK handles authentication, compliance, or integration with your existing security policies?  \nIdentified persona: Business."
    },
    {
      "query": "What industry applications could benefit from quantum scheduling optimization?",
      "reference_contexts": [
        "Industries like manufacturing, logistics, or energy can reduce idle time and increase resource efficiency."
      ],
      "reference_answer": "This use case addresses industrial scheduling challenges.",
      "response": "Quantum scheduling optimization has potential to benefit a wide range of industries where complex scheduling, resource allocation, and timetabling are critical. On the PlanQK platform, use cases are typically described in terms of mapping real-world problems (like scheduling) to mathematical subproblems that quantum algorithms can address. Here are some key industries that could benefit from quantum-enhanced scheduling:\n\n- Transportation & Logistics: Optimizing vehicle routing, delivery schedules, and fleet management to minimize costs and maximize efficiency.\n- Manufacturing: Scheduling machinery and workforce in factories for production line optimization and reduced downtime.\n- Energy: Allocating generation resources and scheduling maintenance for power grids and renewable integration.\n- Telecommunications: Assigning frequencies, scheduling data packets, and optimizing network resource usage.\n- Healthcare: Staff rostering, surgery scheduling, and optimizing resource allocation in hospitals.\n- Finance: Scheduling trades, optimizing resource use for high-frequency trading, and portfolio rebalancing.\n- Aviation & Airports: Gate assignment, crew scheduling, and flight timetabling.\n\nOn PlanQK, you can explore use cases by adding relevant application areas and industries when creating or viewing a use case. The “Details” tab of any use case allows you to specify application areas and industries, helping to illustrate how quantum scheduling can be mapped onto quantum hardware for practical solutions. You can also link algorithms and implementations that are specifically suited to scheduling optimization problems, and see how they relate to different industry needs.\n\nWould you like to see specific scheduling use cases or quantum algorithms on the PlanQK platform? If so, I can guide you to some relevant examples or help you create a new use case entry.\n\nsource: https://docs.planqk.de/community/use-cases.html\n\nIdentified persona: Business"
    },
    {
      "query": "How is quantum computing used to model supply chain disruptions?",
      "reference_contexts": [
        "Quantum circuits simulate uncertainty in supply chains to optimize buffer strategies."
      ],
      "reference_answer": "Quantum simulations evaluate supply chain resilience under uncertainty.",
      "response": "Quantum computing is increasingly being explored to model and mitigate supply chain disruptions due to its ability to handle complex optimization and simulation tasks that are challenging for classical computers. Here’s how quantum computing is typically applied in this area:\n\n1. Optimization Problems: Supply chains involve numerous variables—inventory levels, transportation options, supplier reliability, demand forecasts, etc.—making optimization for cost, efficiency, or resilience computationally intensive. Quantum algorithms (such as Quantum Approximate Optimization Algorithm, QAOA) can potentially solve these problems faster or more accurately than classical algorithms by exploring many possible scenarios in parallel.\n\n2. Scenario Simulation: Quantum computers can simulate complex, probabilistic scenarios, allowing companies to model how disruptions (like natural disasters, geopolitical events, or supplier failures) might propagate through a supply chain. This enables better risk assessment and contingency planning.\n\n3. Real-Time Decision Support: Quantum-enabled services can process large datasets from global supply chains in real time, offering recommendations for rerouting shipments, sourcing alternatives, or adjusting production schedules in response to disruptions.\n\nOn the PlanQK platform, you can explore these approaches using ready-to-use quantum algorithms and SDKs. For example, you can:\n- Start with tutorials and templates for quantum optimization, such as those for solving the Maximum Independent Set problem or integrating with Qiskit and D-Wave annealers.\n- Use service orchestration to build workflows that combine quantum-powered optimization with classical analytics, creating robust supply chain decision tools.\n\nIf you’re interested in practical demonstrations or want to set up a quantum optimization workflow tailored to supply chain challenges, check out these PlanQK resources:\n- Quantum SDK and Service SDK for building and running quantum algorithms: source: https://docs.planqk.de/quickstart.html\n- Tutorials for quantum optimization and integration with popular quantum hardware: source: https://docs.planqk.de/tutorials/tutorial-dwave.html\n- Service orchestration for combining multiple quantum and classical services: source: https://docs.planqk.de/services/orchestration/introduction.html\n\nWould you like a step-by-step guide for modeling a specific supply chain scenario, or are you looking for general recommendations on which algorithms to use?\n\nIdentified persona: Technical"
    },
    {
      "query": "How can hospitals benefit from quantum radiotherapy optimization?",
      "reference_contexts": [
        "It improves patient safety by minimizing healthy tissue exposure while saving planning time."
      ],
      "reference_answer": "More accurate planning leads to better outcomes and resource efficiency.",
      "response": "Hospitals can gain significant advantages from quantum radiotherapy optimization by improving treatment effectiveness and operational efficiency. Quantum algorithms—especially those for combinatorial optimization—can help optimize the delivery of radiation doses, tailoring plans more precisely to individual patient anatomies and tumor shapes. This can potentially reduce side effects, increase the accuracy of tumor targeting, and enable faster treatment planning compared to classical approaches.\n\nSpecific benefits for hospitals include:\n- Improved patient outcomes due to more accurate and personalized radiotherapy plans.\n- Increased throughput in radiotherapy departments by reducing computation times for complex dose optimization problems.\n- Cost savings from more efficient resource usage and reduced planning time.\n- Enhanced ability to tackle cases that are currently challenging for classical algorithms (e.g., multi-target or highly constrained dose planning scenarios).\n- Early adoption of cutting-edge technology, which can differentiate a hospital in the healthcare market.\n\nIf you’re interested in exploring quantum radiotherapy optimization with PlanQK, I recommend checking our available quantum optimization algorithms and relevant healthcare use cases. Would you like to see a specific algorithm demo or learn about integration options for existing hospital IT systems?\n\nsource: https://platform.planqk.de/use-cases  \nsource: https://docs.planqk.de/manage-quantum-jobs.html  \n\nIdentified persona: Business"
    },
    {
      "query": "I manage a battery lab at a car manufacturer. How can quantum ML help classify cell quality more efficiently?",
      "reference_contexts": [
        "Quantum classifiers can detect subtle performance differences earlier in the production process."
      ],
      "reference_answer": "Quantum classifiers improve prediction of cell performance and lifecycle.",
      "response": "Quantum machine learning (QML) can offer significant advantages for classifying battery cell quality, especially as your data grows in volume and complexity. Quantum algorithms can potentially process large datasets faster and uncover subtle patterns that classical methods might miss, which can lead to more accurate early detection of defects and improve overall production yield.\n\nOn the PlanQK platform, you have access to quantum and hybrid quantum-classical machine learning models specifically designed for tasks such as classification, anomaly detection, and regression. These can be leveraged to analyze sensor data, images, or other measurements from your battery cells. By integrating QML into your workflow, you may benefit from:\n\n- Improved classification accuracy due to quantum-enhanced feature extraction.\n- Faster model training and inference for large datasets.\n- The ability to tackle highly complex, nonlinear relationships in your data that are challenging for classical ML.\n\nTo get started, PlanQK provides starter templates, managed services, and SDKs for building and deploying quantum ML solutions. For example, you can use the PLANQK CLI to initialize a quantum ML project, deploy it as a managed service, and easily connect your lab data for automated classification tasks. There are also demos and use cases you can explore to see how others have applied quantum ML in manufacturing and quality control scenarios.\n\nWould you like guidance on a specific type of battery data (e.g., sensor, image, time-series), or are you interested in exploring available PlanQK demos and starter templates for quantum ML classification?  \nsource: https://platform.planqk.de/home  \nIdentified persona: Business"
    },
    {
      "query": "Which types of input data were used to train the quantum model in this battery case?",
      "reference_contexts": [
        "Voltage, current, and impedance data from real battery tests were used."
      ],
      "reference_answer": "Battery cell lab data was used to train classifiers.",
      "response": "The retrieved documents do not contain specific information about the types of input data used to train the quantum model in the battery case. If you can share more details about the battery use case or point to related documentation, I can help you identify the relevant data pools or input schemas commonly used in quantum modeling on PlanQK.\n\nWould you like to explore general guidelines for defining input data for quantum services, or are you seeking information about a particular battery optimization use case listed on PlanQK? Let me know how you'd like to proceed!\n\nIdentified persona: Technical."
    },
    {
      "query": "What kind of data preprocessing is required before passing text to the quantum model?",
      "reference_contexts": [
        "Text is embedded using classical NLP techniques before being fed to the quantum circuit."
      ],
      "reference_answer": "Text is vectorized and embedded prior to quantum input.",
      "response": "To pass text data to a quantum model on PlanQK, you'll need to handle a few key preprocessing steps. PlanQK services expect input data in JSON format, so your raw text must be converted into a structure that the service can accept. Here are the general steps and considerations:\n\n1. Text Encoding:  \n - Most quantum models (especially NLP or optimization services) require text to be tokenized or converted to numerical form before execution. Typical preprocessing includes:\n  • Tokenization (splitting text into words, subwords, or characters).\n  • Optionally, converting tokens into integer indices based on a vocabulary.\n  • For some models, embedding representations may be needed, but if the service handles this internally, you only need to submit the raw or tokenized text.\n\n2. JSON Formatting:  \n - Package your preprocessed data as a JSON object, e.g.:\n  { \"data\": { \"text\": \"your preprocessed text\" }, \"params\": { … } }\n - Input must be passed as a JSON map, either directly or by reference to a data pool file if large (over 1MB) [doc3].\n\n3. Service-specific Requirements:  \n - Each quantum model or service on PlanQK may have specific expectations about input data structure. Always check the API documentation or the OpenAPI schema provided for the service to see required fields (e.g., { \"data\": { \"values\": [...] }, \"params\": { ... } } for numerical input) [doc4][doc5].\n - If using custom containers, test your input locally by placing your JSON-formatted data in input/data.json before running your service [doc10].\n\n4. Size Considerations:  \n - Direct JSON input is limited to 1MB. For larger datasets, use the data pool mechanism and pass a reference object instead [doc3].\n\n5. Additional Preprocessing:  \n - Depending on the quantum algorithm, you may need to normalize, clean, or filter your text data, especially if the model is sensitive to input quality.\n\nWould you like guidance for a specific quantum NLP or text-based model? If you share which service or algorithm you're targeting, I can provide more tailored preprocessing instructions.\n\nIdentified persona: Technical"
    },
    {
      "query": "We manage multi-stage production lines. Can quantum optimization help balance load and reduce downtime?",
      "reference_contexts": [
        "Yes, quantum algorithms optimize task assignments and sequencing across production resources."
      ],
      "reference_answer": "Quantum optimization minimizes scheduling gaps and improves throughput.",
      "response": "Absolutely—quantum optimization can be a game-changer for managing multi-stage production lines, especially when it comes to load balancing and minimizing downtime!\n\nQuantum optimization algorithms are designed to tackle complex, combinatorial problems much more efficiently than traditional methods. In production lines, this means you can optimize scheduling, resource allocation, and workflow sequencing to keep every stage running smoothly and reduce bottlenecks. Quantum approaches can also help identify the best configuration to minimize transition times, allocate tasks dynamically, and even predict maintenance needs to avoid unexpected downtime.\n\nOn PlanQK, there are ready-to-use quantum services and algorithms that specifically target optimization problems, including job-shop scheduling, resource allocation, and supply chain management. You can start by exploring use cases relevant to manufacturing and production optimization in the PlanQK marketplace:\n- Job-shop and flow-shop scheduling\n- Resource and machine allocation\n- Predictive maintenance optimization\n\nWould you like a recommendation for a specific algorithm or service to try out first? Or do you want guidance on integrating PlanQK quantum optimization services into your existing workflow? You can browse optimization services and use cases here: source: https://platform.planqk.de/usecases\n\nIdentified persona: Business"
    },
    {
      "query": "We operate a fleet of delivery vehicles. Can quantum optimization reduce total travel time and fuel consumption?",
      "reference_contexts": [
        "Yes, quantum algorithms help solve complex routing and scheduling tasks more efficiently than classical heuristics."
      ],
      "reference_answer": "Quantum optimization is applied to last-mile delivery routing problems.",
      "response": "Absolutely—quantum optimization is a promising approach for logistics challenges like minimizing total travel time and fuel consumption across a fleet of delivery vehicles. Quantum algorithms excel at solving complex optimization problems, such as the Vehicle Routing Problem (VRP) and variants like the Traveling Salesman Problem (TSP), which are central to delivery fleet management.\n\nPlanQK offers quantum and hybrid optimization services that can help you:\n- Optimize delivery routes to minimize total distance and travel time.\n- Reduce fuel consumption by selecting the most efficient paths.\n- Incorporate constraints like delivery windows, vehicle capacities, and real-time traffic.\n\nBy leveraging quantum backends available on PlanQK, you can experiment with state-of-the-art algorithms that often outperform classical solutions for highly complex scenarios. You can start by running demos, exploring use cases, or integrating your data into quantum optimization workflows.\n\nNext Steps for You:\n1. Explore PlanQK’s quantum optimization use cases and available demos for logistics and routing problems.  \n2. Consider deploying a demo or connecting your fleet data to test quantum optimization on your specific scenario.  \n3. Review service orchestration options to automate and scale your optimization workflows.\n\nIf you’re interested in economic impact or ROI, PlanQK’s services can help you analyze the potential savings in time and fuel costs by comparing quantum-optimized routes with classical solutions.\n\nWould you like help setting up a demo or connecting your fleet data to PlanQK’s optimization services?  \nYou can get started here: source: https://platform.planqk.de/home\n\nIdentified persona: Business"
    },
    {
      "query": "Can quantum anomaly detection help us monitor real-time production data for early defect detection?",
      "reference_contexts": [
        "Yes, quantum-enhanced anomaly detection identifies abnormal sensor patterns that indicate early failure."
      ],
      "reference_answer": "Quantum ML is used to detect anomalies in sensor-based manufacturing data.",
      "response": "Absolutely! Quantum anomaly detection is a promising approach for monitoring real-time production data and identifying early signs of defects. By leveraging quantum algorithms, you can potentially enhance the sensitivity and speed of anomaly detection compared to classical methods, especially in complex, high-dimensional datasets commonly found in industrial environments.\n\nOn PlanQK, you can access quantum and hybrid services that implement anomaly detection algorithms. These services can be integrated into your production monitoring pipelines to flag deviations or abnormal patterns in sensor data, process outputs, or equipment telemetry—helping you catch potential issues before they escalate.\n\nHere’s how you could get started:\n\n- Explore algorithms and use cases related to anomaly detection in the PlanQK Community section, where experts share implementations and real-world examples. This helps you understand which quantum approaches are currently available and how they’ve been applied in production scenarios. source: https://docs.planqk.de/community/overview.html\n- Use the PlanQK Service SDK to integrate quantum anomaly detection services into your existing workflows, allowing for automated, real-time monitoring and alerting. source: https://docs.planqk.de/sdk-reference-service.html\n- Set up service orchestration so that anomaly detection results can trigger follow-up actions (such as automated quality checks or maintenance requests) within your production IT landscape. source: https://docs.planqk.de/services/orchestration/introduction.html\n\nWould you like specific recommendations for quantum anomaly detection services or guidance on how to integrate them into your production system? If you tell me more about your data types, production process, and current monitoring setup, I can suggest the most relevant PlanQK resources and next steps.\n\nIdentified persona: Business"
    },
    {
      "query": "What quantum algorithm is applied to detect anomalies in machine data?",
      "reference_contexts": [
        "A quantum kernel method combined with a support vector machine was used."
      ],
      "reference_answer": "Quantum-enhanced SVM with quantum kernels.",
      "response": "On PlanQK, you can explore quantum algorithms specifically designed for anomaly detection in machine data by browsing the Algorithms section. While the retrieved documents do not specify a single named algorithm for anomaly detection, the platform allows you to search for algorithms tailored to your use case—such as quantum-enhanced clustering, quantum support vector machines, or quantum principal component analysis—which are commonly used for anomaly detection in classical and quantum contexts.\n\nTo find a suitable quantum algorithm, visit the Algorithms area on PlanQK and use the search functionality to filter for “anomaly detection,” “machine data,” or related keywords. This will help you identify implementations and algorithm descriptions contributed by the community that match your needs. You can also link these algorithms to your use case for further exploration and integration with quantum services on PlanQK.\n\nWould you like guidance on searching for specific anomaly detection algorithms, or do you have a particular machine data scenario in mind? If you describe your dataset or anomaly patterns, I can help you pinpoint the most relevant quantum approach on PlanQK!\n\nsource: https://docs.planqk.de/community/algorithms.html\n\nIdentified persona: Technical"
    },
    {
      "query": "Can the quantum model handle custom constraints like vacation days and role qualifications?",
      "reference_contexts": [
        "Yes, the model includes hard and soft constraints such as availability and required skillsets."
      ],
      "reference_answer": "Custom constraints are encoded in the QUBO problem.",
      "response": "Yes, the quantum models and algorithms available on PlanQK can generally be adapted to handle custom constraints such as vacation days and role qualifications. PlanQK provides a variety of quantum and hybrid algorithms for different optimization and scheduling problems, and these constraints can typically be encoded into the problem formulation—whether you’re using a quantum annealing approach (e.g., D-Wave) or gate-based algorithms (e.g., Qiskit on IBM Quantum backends).\n\nTo implement custom constraints:\n- You would define your input data structure to reflect specific requirements, such as unavailable days (vacations) or required skills/qualifications per role.\n- The quantum algorithm is then constructed so that solutions violating these constraints are penalized or excluded, typically by encoding the constraints into the cost function or problem Hamiltonian.\n- When using PlanQK’s Service API, your input JSON can include fields for these constraints. For example, you might pass a list of unavailable days per employee or required qualifications per shift in the \"data\" or \"params\" section of your job input. The backend runtime will pass these to your algorithm implementation, which should handle them appropriately in the optimization step. You can use Pydantic models to define and validate these inputs in your service code for robustness and clarity [doc5].\n\nWould you like help with a specific algorithm or guidance on encoding these constraints in your optimization model? If you share more details about your use case (e.g., workforce scheduling, resource allocation), I can point you to relevant PlanQK tutorials or algorithm templates.\n\nsource: https://docs.planqk.de/services/managed/runtime-interface.html\n\nIdentified persona: Technical"
    },
    {
      "query": "What kind of model is used to classify cancerous cells in this use case?",
      "reference_contexts": [
        "A variational quantum classifier is trained on feature-extracted image data."
      ],
      "reference_answer": "VQC applied to image classification tasks in cancer detection.",
      "response": "There are no details in the retrieved documents specifying a particular model used to classify cancerous cells in a PlanQK use case. The documents focus on general guidelines for describing and linking use cases, input/output data structures for services, and technical deployment instructions. If you are referring to a specific PlanQK use case for cancer cell classification, you may need to consult the details or description field of that use case, which typically contains information about the problem approach, algorithms, and models used. If you have a link or name of the exact use case, I can help you find more targeted information or guide you in submitting such a use case within the PlanQK platform.\n\nCould you clarify which use case or algorithm you mean, or are you looking for recommendations on quantum or AI models suitable for cancer cell classification within PlanQK?\n\nIdentified persona: Business"
    },
    {
      "query": "We want to reduce hospital readmission rates. Can quantum machine learning help us identify high-risk patients?",
      "reference_contexts": [
        "Yes, quantum classifiers can analyze patient histories to predict readmission risks with high accuracy."
      ],
      "reference_answer": "Quantum ML models predict hospital readmission likelihood.",
      "response": "Absolutely—quantum machine learning (QML) can be a powerful tool for identifying patients at high risk of hospital readmission, especially when working with complex, high-dimensional healthcare data.\n\nHow QML Could Help:\n- Quantum-enhanced algorithms can process and analyze large patient datasets to uncover subtle patterns and correlations that might be missed by classical methods.\n- QML models may improve predictive accuracy for identifying high-risk patients, which can directly support proactive care management and reduce readmission rates.\n- PlanQK offers a platform for hosting and running quantum and hybrid quantum-classical machine learning models, making it possible to experiment with these advanced approaches without deep quantum programming expertise.\n\nHow to Get Started on PlanQK:\n1. Explore Demos: You can quickly set up interactive web interfaces for your QML use cases using PlanQK Demos. For a rapid start, use the Gradio starter template or deploy your own web app with Docker. This lets you showcase predictive models and share results with clinicians or stakeholders.\n   - source: https://docs.planqk.de/demos/introduction.html\n\n2. Community & Use Cases: The PlanQK Community section features real-world use cases, algorithm implementations, and expert discussions—an ideal place to learn how others tackle healthcare problems with QML and get feedback on your approach.\n   - source: https://docs.planqk.de/community/overview.html\n\n3. Quantum SDKs: The PlanQK Quantum SDK supports frameworks like Qiskit and Amazon Braket, letting you build and run quantum machine learning models on real quantum hardware and simulators. If you use PennyLane for quantum ML, it's also supported.\n   - source: https://docs.planqk.de/sdk-reference.html\n\n4. Tutorials: There are step-by-step guides for implementing quantum optimization and classification tasks—these can be adapted to healthcare scenarios, such as patient risk prediction.\n\nNext Steps:\n- Are you looking to build a proof-of-concept model, or do you already have healthcare data you'd like to analyze?\n- Would you like recommendations for specific quantum ML algorithms or guidance on integrating classical ML with quantum approaches?\n- Is your team interested in running interactive demos for clinical decision support?\n\nLet me know your current resources and goals, and I can point you to the most relevant PlanQK services and tutorials for your project!\n\nIdentified persona: Business"
    },
    {
      "query": "We manage a portfolio of smart buildings. Can quantum computing help optimize heating and cooling schedules to reduce energy consumption?",
      "reference_contexts": [
        "Yes, quantum algorithms can optimize building control by minimizing energy costs while maintaining comfort levels."
      ],
      "reference_answer": "Quantum optimization is applied to energy-efficient HVAC control in smart buildings.",
      "response": "Absolutely! Quantum computing has strong potential to optimize complex scheduling problems like heating and cooling in smart buildings, where the goal is to balance comfort, cost, and energy use. These types of problems often involve a huge number of variables and constraints—making them ideal candidates for quantum-enhanced optimization.\n\nOn the PlanQK platform, you can leverage quantum algorithms and backends to tackle these kinds of combinatorial optimization tasks. For example, quantum annealers (like those provided by D-Wave, accessible via PlanQK) are well-suited for solving quadratic unconstrained binary optimization (QUBO) problems, which map directly to scheduling and resource allocation challenges in building management.\n\nHere’s how PlanQK can support your use case:\n- Quantum Backends: Access to D-Wave, IBM Quantum, and other hardware/software for optimization problems.\n- Service SDK: Easily integrate quantum services into your building management systems using Python or Docker templates.\n- Tutorials: Step-by-step guides on setting up optimization jobs and integrating with your IT infrastructure.\n- Service Orchestration: Combine multiple services (e.g., weather forecasting, occupancy prediction, and energy optimization) into automated workflows—no code required.\n\nSuggested next steps:\n1. Explore PlanQK’s tutorials on quantum optimization (e.g., using D-Wave for QUBO problems): source: https://docs.planqk.de/tutorials/tutorial-dwave.html\n2. Review available quantum backends and see which fits your data and constraints: source: https://docs.planqk.de/quickstart.html\n3. Consider orchestrating a workflow to integrate quantum optimization with other smart building data sources: source: https://docs.planqk.de/services/orchestration/introduction.html\n\nCould you share more about your building portfolio size, data sources, and any current optimization tools? That’ll help me recommend the best starting point and quantum resources for your scenario.\n\nIdentified persona: Business"
    },
    {
      "query": "Can external factors like weather forecasts or occupancy be included in the optimization?",
      "reference_contexts": [
        "Yes, the model can integrate dynamic inputs such as temperature forecasts or building usage patterns."
      ],
      "reference_answer": "The model accepts external inputs for adaptive optimization.",
      "response": "Absolutely! External factors such as weather forecasts and occupancy data can be integrated into your optimization workflows on PlanQK. These types of data are commonly used as inputs for AI/ML and quantum optimization services, especially in domains like energy management, logistics, and smart buildings.\n\nHere’s how you can approach this on PlanQK:\n\n- Data Integration: You can design your service or workflow to accept external data (e.g., weather, occupancy) as part of the input payload. For example, you might structure your input data to include time series from weather APIs or occupancy sensors.\n- Service Orchestration: With PlanQK’s workflow editor, you can combine multiple services—such as a weather data retrieval service, occupancy prediction, and an optimization solver—in a single orchestrated flow. Each service node can process or transform the data as needed before passing it to the next step in the workflow .\n- Custom Services: If your optimization requires custom logic or integration with external APIs, PlanQK allows you to implement and deploy custom services (using Python, Docker containers, etc.) that fetch and preprocess external data before running the optimization algorithm [doc4].\n- Use Cases: Many PlanQK use cases involve integrating external factors to improve solution quality. For example, smart grid optimization often includes weather and usage forecasts as part of the input data set [doc10].\n\nIf you want to get started, I recommend:\n- Defining your input data schema to include the external factors.\n- Exploring the Workflow Editor to orchestrate multiple services.\n- Reviewing tutorials for custom service creation and orchestration:\n  - Service orchestration example: source: https://docs.planqk.de/services/orchestration/example.html\n  - Custom Docker containers for advanced integration: source: https://docs.planqk.de/services/managed/custom-containers.html\n\nWould you like guidance on connecting a specific external data source, or help designing a workflow for your optimization scenario?\n\nIdentified persona: Technical"
    },
    {
      "query": "What is the goal of simulating the hydrogen molecule on a quantum computer?",
      "reference_contexts": [
        "To validate the accuracy and feasibility of VQE algorithms on small-scale quantum systems."
      ],
      "reference_answer": "Uses VQE to calculate the ground state energy of H₂.",
      "response": "The goal of simulating the hydrogen molecule (H₂) on a quantum computer is to solve quantum chemistry problems more efficiently than classical computers can. Specifically, quantum computers can model the electronic structure of molecules by simulating their quantum behavior directly, using algorithms like the Variational Quantum Eigensolver (VQE) or Quantum Phase Estimation (QPE).\n\nFor the hydrogen molecule, this means computing its ground state energy and understanding its chemical properties with higher accuracy and less computational overhead. Simulating H₂ is considered a foundational benchmark in quantum computing research because it's the simplest molecule with electron correlation, making it a useful starting point for testing quantum algorithms and hardware capabilities. Success in simulating hydrogen paves the way for tackling larger, more complex molecules relevant to material science and pharmaceuticals.\n\nAre you interested in running such simulations on PlanQK, or do you want to learn more about specific quantum chemistry algorithms available on the platform? I can guide you to relevant tutorials and services!\n\nIdentified persona: Technical."
    },
    {
      "query": "Which dataset and features are typically used in fraud detection quantum models?",
      "reference_contexts": [
        "The model is trained on transaction metadata like time, amount, and device ID."
      ],
      "reference_answer": "Uses anonymized transaction metadata for quantum fraud classification.",
      "response": "Fraud detection quantum models typically rely on datasets that contain transaction-level information—these can be sourced from financial institutions, credit card companies, or simulated environments for benchmarking. While the specific dataset used will depend on the business context and data availability, common features include:\n\n- Transaction amount\n- Timestamp/date\n- Merchant category\n- Location (e.g., IP address, country)\n- Device information\n- Account age\n- Historical transaction patterns\n- Flags for previous fraud detection\n- User/customer identifiers\n- Transaction type (online/in-store, payment/refund, etc.)\n- Unusual transaction frequency or volume\n\nIn quantum machine learning, these features are often encoded into quantum states (using techniques like amplitude encoding or angle encoding) so that quantum algorithms—such as Quantum Support Vector Machines (QSVM), Quantum Neural Networks (QNN), or Quantum Kernel methods—can process them for classification tasks.\n\nPlanQK does not enforce a specific dataset, but when creating a use case for fraud detection on the platform, you should thoroughly describe your dataset, features, and how they map to your quantum model. The “Details” tab of a use case is the recommended place to document the initial problem statement, dataset properties, and feature engineering decisions. You can also link associated services, algorithms, and data pools relevant to your use case in the “Relations” tab for better traceability and reproducibility. This documentation helps collaborators and interested users understand your approach and the data you used for quantum fraud detection modeling. For more on documenting datasets and features for your quantum use case, see: source: https://docs.planqk.de/community/use-cases.html\n\nAre you looking for guidance on selecting features for a specific dataset, or would you like recommendations for quantum algorithms and encoding techniques for fraud detection? Let me know your context or the stage of your project, and I can point you to relevant PlanQK resources or example implementations.\n\nIdentified persona: Technical"
    },
    {
      "query": "What features are used to train the quantum model in the readmission prediction task?",
      "reference_contexts": [
        "Structured EHR data like age, diagnosis codes, previous admissions, and length of stay."
      ],
      "reference_answer": "Structured patient data is used as model input.",
      "response": "There are no retrieved documents that directly describe the features used to train the quantum model in the readmission prediction task. If you are looking for details on how to structure input data and parameters for quantum or AI services on PlanQK, the documentation suggests using a JSON object with \"data\" and \"params\" fields, where \"data\" could contain the actual features (e.g., patient information, clinical variables), and \"params\" may hold configuration options for the prediction model. However, the specific features for the readmission prediction task are not listed in the provided sources [doc1][doc7].\n\nTo get more precise information about the feature set for this use case, I recommend checking the details or description section of the relevant use case on the PlanQK platform, or consulting the implementation documentation if available. Would you like guidance on how to define input schemas for your own predictive service, or do you need help locating published use cases on PlanQK?\n\nIdentified persona: Technical"
    }
  ]
}